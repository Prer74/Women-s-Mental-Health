{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328a1517-e6a4-47c5-9af6-fbb4e3aa06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d138d5-d738-4976-b0a9-dacf305e339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'womens_journal_entries.csv'  \n",
    "balanced_final_dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa81f858-0095-41e2-b3d3-360acf7bc1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "                                          statements status\n",
      "0  It's Monday. I feel like I'm going to have a g...  happy\n",
      "1  I'm so grateful to have such a wonderful mothe...  happy\n",
      "2  I am not sure if I should tell you this, but I...    sad\n",
      "3  I can't believe I've been on this diet for 2 w...    sad\n",
      "4  I took a shower today for the first time in 3 ...  happy\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Preview:\")\n",
    "print(balanced_final_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2155c86a-cb24-4441-9b62-50f16859ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "statements    0\n",
      "status        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "print(\"\\nMissing Values:\")\n",
    "print(balanced_final_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4992cea-dd0b-4d2b-88b7-2482b95170cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5002 entries, 0 to 5001\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   statements  5002 non-null   object\n",
      " 1   status      5002 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get basic information about the dataset (e.g., data types, number of entries)\n",
    "print(\"\\nDataset Information:\")\n",
    "balanced_final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a8e6d2-93ba-4fdf-b8bf-32fb9121210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Distribution:\n",
      "status\n",
      "sad      2591\n",
      "happy    2411\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLabel Distribution:\")\n",
    "print(balanced_final_dataset['status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe78770a-6a7f-4bdc-8013-2470a044d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Text Sample:\n",
      "0    its monday i feel like im going to have a good...\n",
      "1    im so grateful to have such a wonderful mother...\n",
      "2    i am not sure if i should tell you this but i ...\n",
      "3    i cant believe ive been on this diet for 2 wee...\n",
      "4    i took a shower today for the first time in 3 ...\n",
      "Name: statements, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows with missing values (if any exist)\n",
    "balanced_final_dataset.dropna(inplace=True)\n",
    "\n",
    "# Basic text cleaning function (converts to lowercase, removes special characters)\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])  # Remove special characters\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the text column\n",
    "balanced_final_dataset['statements'] = balanced_final_dataset['statements'].apply(clean_text)\n",
    "\n",
    "# Verify the cleaning process\n",
    "print(\"\\nCleaned Text Sample:\")\n",
    "print(balanced_final_dataset['statements'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60a480b7-e4b2-44ff-b0fd-0916f9df607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4001 samples\n",
      "Test set size: 1001 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features (X) and labels (y)\n",
    "X = balanced_final_dataset['statements']\n",
    "y = balanced_final_dataset['status']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the training and testing sets\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a53d6fd5-a76f-491b-80c3-665ac34fd1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF training data shape: (4001, 3586)\n",
      "TF-IDF test data shape: (1001, 3586)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize the text data using TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2, max_df=0.85, stop_words='english')\n",
    "\n",
    "# Fit the vectorizer on the training data and transform both the train and test data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Check the dimensions of the TF-IDF vectors\n",
    "print(f\"TF-IDF training data shape: {X_train_tfidf.shape}\")\n",
    "print(f\"TF-IDF test data shape: {X_test_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2eae3b36-18a8-4bac-b40a-db0996b0412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_pred = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the accuracy of the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07bef666-d6f2-4c1e-b6ba-801c74a6ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=60, max_iter=200)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lr_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the accuracy of the Logistic Regression model\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b19096eb-4191-4d61-9aa5-e159a04a0bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=60)\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "dt_pred = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the accuracy of the Decision Tree model\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae336a9b-1888-40d5-b219-c3c266c61616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
